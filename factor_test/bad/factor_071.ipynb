{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5426e292-ebf5-4456-99df-b73fca9d2b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多组测试数据相关性表现：[0.9655371942468839, 0.9655372666470065, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b0c4553-aa81-41e4-9c0a-1642e916f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定所有月份的oneminute数据经过factor_pycode处理后将要保存的位置\n",
    "\n",
    "######################################################################### factor_result_allmonth路径替换\n",
    "output_directory = r'F:\\QuantData\\factor_result_allmonth\\factor_71_VR_t'\n",
    "######################################################################### factor_result_allmonth路径替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b6e32e7-87be-4e7b-b018-00b9c4bef8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数get_factor.给定分钟数据，返回形如'SecuCode''TradeDay'因子值三列的结果数据\n",
    "# 取自 20071_2.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_factor(df): ### df数据表参量名替换\n",
    "    ################################################################################################# factor_pycode代码替换\n",
    "    # 计算上午和下午开盘前30分钟的成交量\n",
    "    df['TradeTime'] = pd.to_datetime(df['TradeTime']).dt.time\n",
    "    morning_volume = df[(df['TradeTime'] >= pd.to_datetime('09:30:00').time()) & (df['TradeTime'] <= pd.to_datetime('10:00:00').time())]\n",
    "    afternoon_volume = df[(df['TradeTime'] >= pd.to_datetime('13:00:00').time()) & (df['TradeTime'] <= pd.to_datetime('13:30:00').time())]\n",
    "    \n",
    "    morning_volume_sum = morning_volume.groupby(['SecuCode', 'TradeDay'])['Volume'].sum().reset_index()\n",
    "    afternoon_volume_sum = afternoon_volume.groupby(['SecuCode', 'TradeDay'])['Volume'].sum().reset_index()\n",
    "    \n",
    "    # 合并上午和下午的成交量数据\n",
    "    volume_ratio = pd.merge(morning_volume_sum, afternoon_volume_sum, on=['SecuCode', 'TradeDay'], suffixes=('_morning', '_afternoon'))\n",
    "    volume_ratio['Volume_Ratio'] = volume_ratio['Volume_morning'] / volume_ratio['Volume_afternoon']\n",
    "    \n",
    "    # 计算时间权重因子\n",
    "    d = 20  # 示例值，可以根据实际情况调整\n",
    "    alpha = 2 / (1 + d)\n",
    "    volume_ratio['Weight'] = (1 - alpha) ** (volume_ratio.groupby('SecuCode').cumcount())\n",
    "    \n",
    "    # 计算成交量比值因子（VR_t）\n",
    "    volume_ratio['Weighted_Volume_Ratio'] = volume_ratio['Volume_Ratio'] * volume_ratio['Weight']\n",
    "    VR_t = volume_ratio.groupby(['SecuCode', 'TradeDay'])['Weighted_Volume_Ratio'].sum().reset_index()\n",
    "    \n",
    "    # 生成最终数据表\n",
    "    result = VR_t[['SecuCode', 'TradeDay', 'Weighted_Volume_Ratio']]\n",
    "    result.columns = ['SecuCode', 'TradeDay', 'VR_t']\n",
    "    ################################################################################################# factor_pycode代码替换\n",
    "\n",
    "    \n",
    "    ############################################################### result结果数据表命名替换  &  因子列命名替换    \n",
    "    result.rename(columns={'VR_t': 'FactorValue'}, inplace=True)\n",
    "    ############################################################### result结果数据表命名替换  &  因子列命名替换    \n",
    "    \n",
    "    ################ result结果数据表命名替换\n",
    "    return result\n",
    "    ################ result结果数据表命名替换 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e84bc65d-5f94-4745-bfde-c7abe9d05bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15832\\3953140260.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['TradeTime'] = pd.to_datetime(df['TradeTime']).dt.time\n"
     ]
    }
   ],
   "source": [
    "# 导入所有one_minute文件，生成相对应factor_result文件，并保存（每个文件对应某年某月）\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def generate_factor_files(input_directory, output_directory, process_function, start_year, start_month, end_year, end_month):\n",
    "    # 生成所有的文件名，按年月顺序\n",
    "    input_file_names = []\n",
    "\n",
    "    # 生成文件名列表，考虑到起始年月和结束年月的数据\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in range(1, 13):\n",
    "            if (year == start_year and month < start_month) or (year == end_year and month > end_month):\n",
    "                continue\n",
    "            file_name = f\"{year}{str(month).zfill(2)}_oneminute.feather\"\n",
    "            input_file_names.append(file_name)\n",
    "\n",
    "    # 创建输出目录（如果不存在）\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # 处理并保存数据\n",
    "    for file in input_file_names:\n",
    "        input_file_path = os.path.join(input_directory, file)\n",
    "        if os.path.exists(input_file_path):  # 检查文件是否存在\n",
    "            # 读取Feather文件\n",
    "            df_oneminute = pd.read_feather(input_file_path)\n",
    "            \n",
    "            # 调用数据处理函数\n",
    "            df_res = process_function(df_oneminute)\n",
    "            \n",
    "            # 定义输出文件名\n",
    "            year_month = file[:6]  # 提取文件名前6个字符作为年月\n",
    "            output_file_name = f\"{year_month}_factor_result.feather\"\n",
    "            output_file_path = os.path.join(output_directory, output_file_name)\n",
    "            \n",
    "            # 保存处理后的DataFrame为Feather文件\n",
    "            df_res.to_feather(output_file_path)\n",
    "            \n",
    "            # print(f\"Processed and saved {output_file_path}\")\n",
    "        else:\n",
    "            print(f\"File {file} does not exist.\")\n",
    "\n",
    "# one_minute数据存放的位置\n",
    "input_directory = r'F:\\QuantData\\minute_data'\n",
    "\n",
    "# 起始年月和结束年月（回测区间）\n",
    "start_year, start_month = 2015, 1\n",
    "# end_year, end_month = 2015, 1\n",
    "end_year, end_month = 2024, 7\n",
    "\n",
    "# 生成所有factor_result文件\n",
    "generate_factor_files(input_directory, output_directory, get_factor, start_year, start_month, end_year, end_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edb52a0d-9693-4c8a-962b-dda92a5ea32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每日高开低收数据df_Day_allmonth（201501-202407）把前面计算得到的factor_result数据全部整合进去\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "df_Day_allmonth = pd.read_feather('F:\\\\QuantData\\\\AShareEODPrices_allmonth.feather')\n",
    "\n",
    "# 确保 TradeDay 列转换为日期时间格式\n",
    "df_Day_allmonth['TradeDay'] = pd.to_datetime(df_Day_allmonth['TradeDay'])\n",
    "\n",
    "output_file_names = [f for f in os.listdir(output_directory) if f.endswith('_factor_result.feather')]\n",
    "\n",
    "# 先合并所有factor_result文件，再与df_Day_allmonth合并\n",
    "list_res = []\n",
    "for file in output_file_names:\n",
    "    output_file_path = os.path.join(output_directory, file)\n",
    "    \n",
    "    # 读取Feather文件\n",
    "    df_res = pd.read_feather(output_file_path)\n",
    "    list_res.append(df_res)\n",
    "\n",
    "df_factor_allmonth = pd.concat(list_res)\n",
    "\n",
    "# 确保 TradeDay 列转换为日期时间格式\n",
    "df_factor_allmonth['TradeDay'] = pd.to_datetime(df_factor_allmonth['TradeDay'])\n",
    "\n",
    "# 与df_Day_allmonth合并\n",
    "df_merge = pd.merge(df_factor_allmonth, df_Day_allmonth, on=['SecuCode', 'TradeDay'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03bb84c-82e1-4bd8-998b-cec89afe1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对每个交易日进行横截面市值中性化处理（消除市值对因子值的影响）\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def neutralize_by_mv(df, factor):\n",
    "    df = df.copy()\n",
    "    df['logMV'] = np.log(df['TotalMV'].replace(0, np.nan))  # 避免log(0)带来的问题\n",
    "    neutralized_values = []\n",
    "\n",
    "    for date, group in df.groupby('TradeDay'):\n",
    "        group = group.dropna(subset=[factor, 'logMV']).copy()  # 确保 group 是一个副本\n",
    "        if group.empty:\n",
    "            continue\n",
    "        y = group[factor]\n",
    "        X = sm.add_constant(group['logMV'])\n",
    "        if len(X) > 1:  # 确保有足够的数据点进行回归\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            group[factor + '_neu'] = model.resid\n",
    "        else:\n",
    "            group[factor + '_neu'] = np.nan\n",
    "        neutralized_values.append(group)\n",
    "\n",
    "    return pd.concat(neutralized_values)\n",
    "    \n",
    "# FactorValue经上述中性化操作得到FactorValue_neu\n",
    "df_PT = neutralize_by_mv(df_merge, 'FactorValue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b092d899-3ca3-4542-99e8-3bcd46caef5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bin edges must be unique: Index([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype='float64', name='FactorValue_neu').\nYou can drop duplicate edges by setting the 'duplicates' kwarg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m month_data \u001b[38;5;241m=\u001b[39m df_PT[df_PT[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTradeDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m month_end_day]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# 对FactorValue_neu进行十分组\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m month_data\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFactorValue_rank\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mqcut(month_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFactorValue_neu\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m10\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     47\u001b[0m returns \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# 选出第x组的股票\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\quant\\Lib\\site-packages\\pandas\\core\\reshape\\tile.py:340\u001b[0m, in \u001b[0;36mqcut\u001b[1;34m(x, q, labels, retbins, precision, duplicates)\u001b[0m\n\u001b[0;32m    336\u001b[0m quantiles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, q \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m is_integer(q) \u001b[38;5;28;01melse\u001b[39;00m q\n\u001b[0;32m    338\u001b[0m bins \u001b[38;5;241m=\u001b[39m x_idx\u001b[38;5;241m.\u001b[39mto_series()\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mquantile(quantiles)\n\u001b[1;32m--> 340\u001b[0m fac, bins \u001b[38;5;241m=\u001b[39m _bins_to_cuts(\n\u001b[0;32m    341\u001b[0m     x_idx,\n\u001b[0;32m    342\u001b[0m     Index(bins),\n\u001b[0;32m    343\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m    344\u001b[0m     precision\u001b[38;5;241m=\u001b[39mprecision,\n\u001b[0;32m    345\u001b[0m     include_lowest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    346\u001b[0m     duplicates\u001b[38;5;241m=\u001b[39mduplicates,\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _postprocess_for_cut(fac, bins, retbins, original)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\quant\\Lib\\site-packages\\pandas\\core\\reshape\\tile.py:443\u001b[0m, in \u001b[0;36m_bins_to_cuts\u001b[1;34m(x_idx, bins, right, labels, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_bins) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m duplicates \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBin edges must be unique: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(bins)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can drop duplicate edges by setting the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduplicates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m kwarg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m         )\n\u001b[0;32m    447\u001b[0m     bins \u001b[38;5;241m=\u001b[39m unique_bins\n\u001b[0;32m    449\u001b[0m side: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m right \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Bin edges must be unique: Index([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype='float64', name='FactorValue_neu').\nYou can drop duplicate edges by setting the 'duplicates' kwarg"
     ]
    }
   ],
   "source": [
    "# 对FactorValue_neu进行十分组多空对冲净值走势分析，绘制回测曲线并计算年化收益率等指标\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 如果分组序号与因子值呈相反关系，则需要将因子值取负，从而得到倒置的分组序号\n",
    "# df_PT['FactorValue_neu'] = -df_PT['FactorValue_neu']\n",
    "\n",
    "# 计算每支股票每天的收益率\n",
    "df_PT['Return'] = df_PT['ClosePrice'] /  df_PT['PreClosePrice'] - 1\n",
    "\n",
    "# 创建一个字典用于保存每组的净值\n",
    "net_values = {i: pd.DataFrame(columns=['Month', 'NetValue']) for i in range(1, 11)}\n",
    "long_short_net_value = pd.DataFrame(columns=['Month', 'NetValue'])\n",
    "\n",
    "# 自动分析回测区间的开始和结束日期\n",
    "df_PT['TradeDay'] = pd.to_datetime(df_PT['TradeDay'])\n",
    "start_date = df_PT['TradeDay'].min().strftime('%Y-%m')\n",
    "end_date = df_PT['TradeDay'].max().strftime('%Y-%m')\n",
    "\n",
    "# 初始化每组的净值为1\n",
    "initial_net_value = 1\n",
    "for i in range(1, 11):\n",
    "    net_values[i] = pd.concat([net_values[i], pd.DataFrame({'Month': [start_date], 'NetValue': [initial_net_value]})])\n",
    "\n",
    "long_short_net_value = pd.concat([long_short_net_value, pd.DataFrame({'Month': [start_date], 'NetValue': [initial_net_value]})])\n",
    "\n",
    "# 计算每个月的末日\n",
    "df_PT['Month'] = df_PT['TradeDay'].dt.to_period('M')\n",
    "end_of_month = df_PT.groupby('Month')['TradeDay'].max().reset_index()\n",
    "\n",
    "# 新增logReturn列\n",
    "df_PT['logReturn'] = np.log(df_PT['Return'] + 1)\n",
    "\n",
    "# 循环处理每个月的数据\n",
    "for i in range(len(end_of_month) - 1):\n",
    "    month_end_day = end_of_month.iloc[i]['TradeDay']\n",
    "    next_month_end_day = end_of_month.iloc[i + 1]['TradeDay']\n",
    "\n",
    "    # 获取该月最后一天的所有股票数据\n",
    "    month_data = df_PT[df_PT['TradeDay'] == month_end_day].copy()\n",
    "    \n",
    "    # 对FactorValue_neu进行十分组\n",
    "    month_data.loc[:, 'FactorValue_rank'] = pd.qcut(month_data['FactorValue_neu'], 10, labels=False) + 1\n",
    "\n",
    "    returns = {}\n",
    "\n",
    "    for group in range(1, 11):\n",
    "        # 选出第x组的股票\n",
    "        group_stocks = month_data[month_data['FactorValue_rank'] == group]['SecuCode'].values\n",
    "\n",
    "        # 获取下个月这组股票的数据\n",
    "        next_month_data = df_PT[(df_PT['TradeDay'] > month_end_day) & (df_PT['TradeDay'] <= next_month_end_day) & \n",
    "                                (df_PT['SecuCode'].isin(group_stocks))]\n",
    "\n",
    "        # 计算每支股票的月收益率\n",
    "        next_month_log_returns = next_month_data.groupby('SecuCode')['logReturn'].sum()\n",
    "        next_month_returns = np.exp(next_month_log_returns) - 1\n",
    "\n",
    "        # 计算第x组股票的平均月收益率\n",
    "        avg_return = next_month_returns.mean()\n",
    "        returns[group] = avg_return\n",
    "\n",
    "        # 计算新的净值\n",
    "        new_net_value = net_values[group].iloc[-1]['NetValue'] * (1 + avg_return)\n",
    "        net_values[group] = pd.concat([net_values[group], pd.DataFrame({'Month': [str(next_month_end_day)[:7]], 'NetValue': [new_net_value]})])\n",
    "\n",
    "    # 计算long-short策略的净值\n",
    "    long_short_return = (1 + returns[10]) / (1 + returns[1]) - 1\n",
    "    new_long_short_net_value = long_short_net_value.iloc[-1]['NetValue'] * (1 + long_short_return)\n",
    "    long_short_net_value = pd.concat([long_short_net_value, pd.DataFrame({'Month': [str(next_month_end_day)[:7]], 'NetValue': [new_long_short_net_value]})])\n",
    "\n",
    "# 绘制净值曲线\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for group in range(1, 11):\n",
    "    plt.plot(net_values[group]['Month'], net_values[group]['NetValue'], linestyle='-', label=f'Group {group}')\n",
    "\n",
    "plt.plot(long_short_net_value['Month'], long_short_net_value['NetValue'], linestyle='--', color='black', label='Long-Short')\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Net Value')\n",
    "plt.title('Net Value Curves for Groups 1 to 10 and Long-Short Strategy Based on FactorValue_neu')\n",
    "plt.legend()\n",
    "\n",
    "# 设置横轴每三个月标注一次\n",
    "xticks = np.arange(0, len(long_short_net_value), step=3)\n",
    "xlabels = [long_short_net_value['Month'].iloc[i] for i in xticks]\n",
    "plt.xticks(ticks=xticks, labels=xlabels, rotation=45)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 计算long-short策略的绩效指标\n",
    "long_short_net_value['Return'] = long_short_net_value['NetValue'].pct_change()\n",
    "\n",
    "# 年化收益率\n",
    "annual_return = (long_short_net_value['NetValue'].iloc[-1] / long_short_net_value['NetValue'].iloc[0]) ** (12 / (len(long_short_net_value) - 1)) - 1\n",
    "\n",
    "# 年化波动率\n",
    "annual_volatility = long_short_net_value['Return'].std() * np.sqrt(12)\n",
    "\n",
    "# 信息比率\n",
    "information_ratio = annual_return / annual_volatility\n",
    "\n",
    "# 月度胜率\n",
    "monthly_win_rate = (long_short_net_value['Return'] > 0).mean()\n",
    "\n",
    "# 最大回撤率\n",
    "rolling_max = long_short_net_value['NetValue'].cummax()\n",
    "drawdown = (long_short_net_value['NetValue'] - rolling_max) / rolling_max\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "# 打印结果\n",
    "print(f\"Annual Return: {annual_return:.2%}\")\n",
    "print(f\"Annual Volatility: {annual_volatility:.2%}\")\n",
    "print(f\"Information Ratio: {information_ratio:.2f}\")\n",
    "print(f\"Monthly Win Rate: {monthly_win_rate:.2%}\")\n",
    "print(f\"Max Drawdown: {max_drawdown:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c3b3f-916c-45c5-85bb-1fa7bfa90c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
