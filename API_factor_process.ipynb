{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10964b5a-41c7-4fe9-8e4a-bf3eb2b2253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多次输出结果（正确结果），互相比对，选择重复度最高的\n",
    "# 与code文件夹平行位置有个文件env用来存放api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6078d3-1cb3-47c2-befa-8e86637f62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from openai import OpenAI, OpenAIError\n",
    "import time\n",
    "import base64\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# 设置 API 密钥（省着点用。。）\n",
    "# api_key = ' '\n",
    "# openai.api_base = 'https://api.gpts.vin'\n",
    "# openai.api_key = ' '\n",
    "# 初始化 OpenAI 客户端\n",
    "# client = OpenAI(api_key=api_key)\n",
    "env_path = Path(__file__).resolve().parent.parent / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://one-api.guanzhao12.com/v1\",\n",
    "    api_key=os.getenv(\"API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0394d78-6ee6-4f89-bd90-25abdada2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import streamlit as st\n",
    "# from openai import OpenAI, OpenAIError\n",
    "# import time\n",
    "# import base64\n",
    "\n",
    "# # 设置 API 密钥（购买于淘宝）\n",
    "# client = OpenAI(\n",
    "#     base_url=\"https://apikeyplus.com/v1\",\n",
    "#     api_key=\" \"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecaeda56-9f07-4a65-b7b7-d178a38114fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 测试案例\n",
    "\n",
    "# prompt=\"帮我写一个一百字作文\"\n",
    "# response = client.chat.completions.create(\n",
    "#     # model=\"gpt-4o\",\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": [\n",
    "#                 {\"type\": \"text\", \"text\": prompt}\n",
    "#             ],\n",
    "#         },  # 将图片数据作为二进制格式传递\n",
    "#     ],\n",
    "#     max_tokens = 2000,\n",
    "#     temperature = 0.5\n",
    "# )\n",
    "# print(response.choices[0].message.content)\n",
    "# # print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fe064db-9336-4964-bd29-59622c7073c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据提示词、附件图片和温度，返回GPT生成文本\n",
    "# 设置默认温度为0.5；温度可在0-1间调整，越小则回答越保守，越大则回答越具创造性\n",
    "def generateGPTtext(prompt, file_path = \"NONE\", temp = 0.5): \n",
    "    # 如果仅有提示词\n",
    "    if file_path == \"NONE\": \n",
    "        # 发送文本生成请求\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                # model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": prompt}\n",
    "                        ],\n",
    "                    },  # 将图片数据作为二进制格式传递\n",
    "                ],\n",
    "                max_tokens = 2000,\n",
    "                temperature = temp\n",
    "            )\n",
    "        except OpenAIError as e:\n",
    "            # OpenAI API 的一般错误\n",
    "            print(\"OpenAI API 错误\")\n",
    "            print(e)\n",
    "        except Exception as e:\n",
    "            # 其他错误\n",
    "            print(\"错误\")\n",
    "            print(e)\n",
    "            \n",
    "    # 如果有提示词和附件图片\n",
    "    else:\n",
    "        # 读取并编码图片\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as image_file:\n",
    "                image_data = image_file.read()\n",
    "                image_base64 = base64.b64encode(image_data).decode()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"文件 '{file_path}' 不存在。\")\n",
    "            exit(1)\n",
    "        # 发送文本生成请求\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                # model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": prompt},\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"},\n",
    "                            },\n",
    "                        ],\n",
    "                    },\n",
    "                ],\n",
    "                max_tokens = 2000,\n",
    "                temperature = temp\n",
    "            )\n",
    "        except OpenAIError as e:\n",
    "            # OpenAI API 的一般错误\n",
    "            print(\"OpenAI API 错误\")\n",
    "            print(e)\n",
    "        except Exception as e:\n",
    "            # 其他错误\n",
    "            print(\"错误\")\n",
    "            print(e)\n",
    "            \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b10272-88e2-41c3-9598-52c9291b9561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 截取code_string中代码的部分，并根据code_index命名后保存到本地\n",
    "def get_python_code(code_string, code_index):\n",
    "    import re\n",
    "    import os\n",
    "    # 使用正则表达式提取 Python 代码块\n",
    "    match = re.search(r'```python\\n(.*?)\\n```', code_string, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        python_code = match.group(1)\n",
    "        code_name = 'code_' + str(code_index) + '.py'\n",
    "        save_path = 'F:\\\\QuantData\\\\factor_pycode'\n",
    "        # 构建完整的文件路径\n",
    "        full_path = os.path.join(save_path, code_name)\n",
    "         # 保存为 .py 文件，使用 UTF-8 编码，指定命名和位置\n",
    "        with open(full_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(python_code)\n",
    "\n",
    "        return True\n",
    "        \n",
    "    else:\n",
    "        print(\"未找到 Python 代码块\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3210de65-34d6-4ad2-93fa-8251bad38fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据上次生成的代码以及产生的报错信息，生成新的代码\n",
    "def regenerate_code(code_string, code_index, error_info):\n",
    "    print(error_info)\n",
    "    prompt = str(code_string) + \"\\n 以上代码运行有误，请根据以下报错信息，重新生成代码：\\n\" + str(error_info)\n",
    "    \n",
    "    code_string = generateGPTtext(prompt)\n",
    "\n",
    "    # 更新code_string在本地的txt文件\n",
    "    file_path = 'F:\\\\QuantData\\\\factor_code_string\\\\error_update_' + str(code_index) + '.txt' \n",
    "    \n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(code_string)\n",
    "    \n",
    "    # 截取的代码文件会直接保存到本地等待之后调用，因此无需作为函数返回值\n",
    "    get_python_code(code_string, code_index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f59d39-ab41-4227-b7e1-ee1549b184cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据因子图片给出对因子的初步分析\n",
    "def step1(file_path):\n",
    "\n",
    "    prompt = \"图片介绍了一个用于评价股票的因子，请详细拆分并一步一步给出这个因子的计算方法，以及因子的含义与逻辑\" + \\\n",
    "            \"\\n输出内容使用Latex格式，能在Overleaf中通过编译)\"\n",
    "    \n",
    "    # file_path = 'F:\\\\QuantData\\\\image\\\\factor\\\\factor.png' # 选择图片文件的路径\n",
    "    # file_path = 'F:\\\\QuantData\\\\image\\\\factor\\\\factor1.jpg'\n",
    "    \n",
    "    factor_analysis = generateGPTtext(prompt, file_path)\n",
    "    \n",
    "    return factor_analysis\n",
    "    \n",
    "    # print(factor_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa7531db-d8e2-4a40-9e82-425888486ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提供具体df，生成计算因子的Python代码\n",
    "def step2(factor_analysis, code_index):\n",
    "\n",
    "    prompt = factor_analysis + \\\n",
    "    \"需要处理的股票数据共有以下这些列：SecuCode: 股票代码；TradeDay: 交易日期；TradeTime: 交易时间（精确到分钟），\\\n",
    "    每天上午09:30:00-11:30:00，下午13:00:00-15:00:00，其他时间不交易；PreClosePrice: 前一分钟收盘价；OpenPrice: 开盘价；HighPrice: 最高价；LowPrice: 最低价；\\\n",
    "    ClosePrice: 收盘价;Amount: 成交金额;Volume: 成交量;TradesCount: 成交笔数。\\\n",
    "    原文件储存在'F:\\\\QuantData\\\\minute_data'，文件名为'202406_oneminute.feather'（请不要尝试读取原文件，因为可能数据量很大）。\\\n",
    "    根据这个数据表，先分析上面的因子是否可以由该数据表的列信息计算得到，若否，给出不能计算的原因，只要存在无法计算的元素，就不要输出任何代码；若是，给出上面因子计算的Python代码\" + \\\n",
    "    \"其中命令包含从本地读取指定数据文件，最后生成数据表仅包含'SecuCode','TradeDay'和所求得的因子值这三列，并以feather格式保存到本地\\\n",
    "    （F:\\\\QuantData\\\\factor_result），命名为'df_'\" + str(code_index) + \\\n",
    "    \"代码风格要求：（1）尽可能对原数据表进行列操作，计算过程中产生的中间变量可视情况合并到原数据表中，用于后面的计算；（2）尽可能减少使用agg，apply；\" \\\n",
    "    + \"（3）在开头包含import numpy as np, 且不要包含import feather\" \\\n",
    "    + \"（4）打印保存代码的路径\"\n",
    "    \n",
    "    file_path = 'F:\\\\QuantData\\\\image\\\\df.png' # 股票数据图片文件的路径\n",
    "    \n",
    "    code_string = generateGPTtext(prompt, file_path, 0.5) # 设置低温度，为了使回答尽可能严谨（尤其是当无法计算时，要忠实地给出结论）\n",
    "\n",
    "    # code_string保存为txt文件，便于检查\n",
    "    file_path = 'F:\\\\QuantData\\\\factor_code_string\\\\' + str(i) + '.txt' \n",
    "    \n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(code_string)\n",
    "\n",
    "    # 检验code_string中是否包含 Python 代码，若否，则说明该因子无法通过现有数据计算得到\n",
    "    if_code = get_python_code(code_string, code_index)\n",
    "\n",
    "    return code_string, if_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0d5a957-4848-4b5b-b5c3-95fb970a6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行上面分析得到的代码，如果报错，则根据错误信息重新生成代码，直到运行成功\n",
    "def step3(code_string, code_index):\n",
    "\n",
    "    import subprocess\n",
    "    \n",
    "    # 从指定路径获取指定脚本文件\n",
    "    script_path = 'F:\\\\QuantData\\\\factor_pycode\\\\'\n",
    "    script_name = script_path + 'code_' + str(code_index) + '.py'\n",
    "    # 记录重复运行次数（有报错时）\n",
    "    try_count = 1\n",
    "    # 用于累计历史报错信息\n",
    "    all_error_info = ''\n",
    "    \n",
    "    while try_count < 4:\n",
    "        try:\n",
    "            # 使用 subprocess.run 执行脚本并捕获输出\n",
    "            result = subprocess.run(\n",
    "                ['python', script_name],   # 执行的命令\n",
    "                capture_output=True,        # 捕获标准输出和标准错误\n",
    "                text=True,                  # 将输出解码为字符串\n",
    "                check=True                  # 如果脚本返回非零状态码则抛出异常\n",
    "            )\n",
    "            # 打印脚本的标准输出\n",
    "            print(\"标准输出:\\n\", result.stdout)\n",
    "            return result.stdout\n",
    "            break # 若生成的代码运行成功，则退出\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            # 打印脚本的标准错误 (具体错误内容)\n",
    "            # print(\"标准错误:\\n\", e.stderr)\n",
    "            print(\"标准错误:\")\n",
    "            \n",
    "            # 打印错误代码\n",
    "            print(\"错误代码:\", e.returncode)\n",
    "    \n",
    "            print(\"重复运行次数：\", try_count)\n",
    "            try_count = try_count + 1\n",
    "\n",
    "            # 将历史报错信息进行累加\n",
    "            all_error_info = all_error_info + e.stderr + '\\n'\n",
    "            # 重新生成代码\n",
    "            regenerate_code(code_string, code_index, all_error_info)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # 处理其他可能的异常\n",
    "            print(\"发生异常:\\n\", e)\n",
    "    \n",
    "            break\n",
    "            \n",
    "    # 如果连续报错以及连续生成代码超过三次，则放弃这个因子\n",
    "    return \"ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81de4077-d151-458b-8b27-a583d6fdab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取最终结果数据文件的路径\n",
    "def step4(path_text):\n",
    "    # 显示最终得到的结果数据\n",
    "    prompt = path_text + \\\n",
    "    \"请直接给出路径，用双斜杠线，不要带任何其他内容\"\n",
    "    \n",
    "    result_path = generateGPTtext(prompt, \"NONE\", 0)\n",
    "    \n",
    "    print(result_path)\n",
    "    \n",
    "    return result_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1e50d73-770a-40a5-9d9e-0506a173b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 识别因子图片，结果保存为txt文件\n",
    "\n",
    "# start_idx = 123  # 准备测试因子序列的首个\n",
    "# end_idx = 232   # 准备测试因子序列的末个\n",
    "\n",
    "# for i in range(start_idx, end_idx + 1): # 选择需要处理的因子\n",
    "#     # factor_reliable = True # 初始默认该因子可靠\n",
    "#     factor_image_path = 'F:\\\\QuantData\\\\factor_image\\\\' + str(i) + '.png' # 因子图片文件的路径\n",
    "    \n",
    "#     # 根据因子图片给出对因子的初步分析\n",
    "#     step1_ans = step1(factor_image_path)\n",
    "\n",
    "#     # 因子的初步分析保存为txt文件，便于后面进一步修改和调整\n",
    "#     file_path = 'F:\\\\QuantData\\\\factor_image_analysis\\\\' + str(i) + '.txt' \n",
    "    \n",
    "#     with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "#         file.write(step1_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8858b20f-d51d-4856-8064-fcc4e5127aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准输出:\n",
      " Result saved to: F:/QuantData/factor_result/df_20109_1.feather\n",
      "\n",
      "F:\\\\QuantData\\\\factor_result\\\\df_20109_1.feather\n",
      "        SecuCode  TradeDay      RS_t\n",
      "0      000001.SZ  20240603  0.000120\n",
      "1      000001.SZ  20240604  0.000099\n",
      "2      000001.SZ  20240605  0.000092\n",
      "3      000001.SZ  20240606  0.000070\n",
      "4      000001.SZ  20240607  0.000082\n",
      "...          ...       ...       ...\n",
      "98305  900957.SH  20240621  0.005438\n",
      "98306  900957.SH  20240624  0.004505\n",
      "98307  900957.SH  20240625  0.004590\n",
      "98308  900957.SH  20240626  0.001496\n",
      "98309  900957.SH  20240627  0.002272\n",
      "\n",
      "[98310 rows x 3 columns]\n",
      "含有NaN数量： 0\n",
      "标准输出:\n",
      " Results saved to F:/QuantData/factor_result/df_20109_2.feather\n",
      "\n",
      "F:\\\\QuantData\\\\factor_result\\\\df_20109_2.feather\n",
      "        SecuCode  TradeDay      RS_t\n",
      "0      000001.SZ  20240603  0.000120\n",
      "1      000001.SZ  20240604  0.000099\n",
      "2      000001.SZ  20240605  0.000092\n",
      "3      000001.SZ  20240606  0.000070\n",
      "4      000001.SZ  20240607  0.000082\n",
      "...          ...       ...       ...\n",
      "98305  900957.SH  20240621  0.005438\n",
      "98306  900957.SH  20240624  0.004505\n",
      "98307  900957.SH  20240625  0.004590\n",
      "98308  900957.SH  20240626  0.001496\n",
      "98309  900957.SH  20240627  0.002272\n",
      "\n",
      "[98310 rows x 3 columns]\n",
      "含有NaN数量： 0\n",
      "标准输出:\n",
      " 结果已保存到: F:/QuantData/factor_result/df_20109_3.feather\n",
      "\n",
      "F:\\\\QuantData\\\\factor_result\\\\df_20109_3.feather\n",
      "        SecuCode  TradeDay      RS_t\n",
      "0      000001.SZ  20240603  0.000120\n",
      "1      000001.SZ  20240604  0.000099\n",
      "2      000001.SZ  20240605  0.000092\n",
      "3      000001.SZ  20240606  0.000070\n",
      "4      000001.SZ  20240607  0.000082\n",
      "...          ...       ...       ...\n",
      "98305  900957.SH  20240621  0.005438\n",
      "98306  900957.SH  20240624  0.004505\n",
      "98307  900957.SH  20240625  0.004590\n",
      "98308  900957.SH  20240626  0.001496\n",
      "98309  900957.SH  20240627  0.002272\n",
      "\n",
      "[98310 rows x 3 columns]\n",
      "含有NaN数量： 0\n",
      "df_corr:\n",
      "                     result_1  result_2  result_3\n",
      "TradeDay SecuCode                               \n",
      "20240603 000001.SZ  0.000120  0.000120  0.000120\n",
      "20240604 000001.SZ  0.000099  0.000099  0.000099\n",
      "20240605 000001.SZ  0.000092  0.000092  0.000092\n",
      "20240606 000001.SZ  0.000070  0.000070  0.000070\n",
      "20240607 000001.SZ  0.000082  0.000082  0.000082\n",
      "...                      ...       ...       ...\n",
      "20240621 900957.SH  0.005438  0.005438  0.005438\n",
      "20240624 900957.SH  0.004505  0.004505  0.004505\n",
      "20240625 900957.SH  0.004590  0.004590  0.004590\n",
      "20240626 900957.SH  0.001496  0.001496  0.001496\n",
      "20240627 900957.SH  0.002272  0.002272  0.002272\n",
      "\n",
      "[98310 rows x 3 columns]\n",
      "[1.0, 1.0, 1.0]\n",
      "第109个因子结果可靠\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "factor_reliable_list = [] # 记录每个因子的可靠情况，第一列表示因子序号，第二列为True或者False\n",
    "\n",
    "start_idx = 109  # 准备测试因子序列的首个\n",
    "end_idx = 109    # 准备测试因子序列的末个\n",
    "gp = 2          # 测试轮次\n",
    "rt = 3          # 同一因子测试次数\n",
    "\n",
    "for i in range(start_idx, end_idx + 1):\n",
    "    factor_reliable = True # 初始默认该因子可靠\n",
    "\n",
    "    # # 直接读取因子图片\n",
    "    # factor_image_path = 'F:\\\\QuantData\\\\factor_image\\\\' + str(i) + '.jpeg'\n",
    "    # # 根据因子图片给出对因子的初步分析\n",
    "    # step1_ans = step1(factor_image_path)\n",
    "\n",
    "    # 已有识别因子图片后得到的txt文件，读取txt文件\n",
    "    factor_txt_path = 'F:\\\\QuantData\\\\factor_image_analysis\\\\' + str(i) + '.txt' \n",
    "    \n",
    "    with open(factor_txt_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        step1_ans = file.read()\n",
    "\n",
    "    \n",
    "    dfs = []\n",
    "    for j in range(1, rt + 1): # 同一因子连续跑出rt个结果\n",
    "        code_index = str(10000 * gp + i) + '_' + str(j)\n",
    "        \n",
    "        # 提供具体df，生成计算因子的Python代码\n",
    "        step2_ans, if_code = step2(step1_ans, code_index)\n",
    "\n",
    "        if if_code: # 如果存在 Python 代码，则运行上面分析得到的代码，如果报错，则根据错误信息重新生成代码，直到运行成功\n",
    "            \n",
    "            step3_ans = step3(step2_ans, code_index) \n",
    "            if step3_ans == 'ERROR':\n",
    "                print(\"第\"+str(i)+\"个因子\"+\"结果不可靠,因为多次生成代码仍然报错\\n\")\n",
    "                factor_reliable = False\n",
    "                break\n",
    "        else: # 如果不存在 Python 代码，则直接宣布该因子无效\n",
    "            print(\"第\"+str(i)+\"个因子\"+\"结果不可靠,因为该因子无法通过现有数据计算得到\\n\")\n",
    "            factor_reliable = False\n",
    "            break\n",
    "        \n",
    "        # 获取最终结果数据文件的路径\n",
    "        step4_ans = step4(step3_ans)\n",
    "    \n",
    "        df = pd.read_feather(step4_ans)\n",
    "\n",
    "        # 判断df是否满足格式要求：恰有三列数据；列名依次为'SecuCode''TradeDay'和因子值；因子值有一半以上不是NaN；没有重复行\n",
    "        # 如果不满足，需要重新生成 Python 代码\n",
    "        try_count = 1\n",
    "        while not (df.shape[1] == 3 and list(df.columns[:2]) == ['SecuCode', 'TradeDay'] and not df.duplicated(subset=['TradeDay', 'SecuCode']).any() and df.iloc[:, -1].isna().sum() < len(df) / 2 and df.iloc[:, -1].eq(0).sum() < len(df) / 2):\n",
    "            \n",
    "            if not (df.shape[1] == 3 and list(df.columns[:2]) == ['SecuCode', 'TradeDay']):\n",
    "                print(\"列数与列名不符\")\n",
    "            elif df.duplicated(subset=['TradeDay', 'SecuCode']).any():\n",
    "                print(\"重复索引\")\n",
    "            else:\n",
    "                print(\"NaN太多或0太多\")\n",
    "            \n",
    "            if try_count == 3:\n",
    "                try_count = try_count + 1\n",
    "                break\n",
    "            else:\n",
    "                print(\"df格式不满足要求，重新生成代码\")\n",
    "                step2_ans = step2(step1_ans, code_index)\n",
    "                step3_ans = step3(step2_ans, code_index)\n",
    "                step4_ans = step4(step3_ans)\n",
    "                df = pd.read_feather(step4_ans)\n",
    "                try_count = try_count + 1\n",
    "                \n",
    "        if try_count == 4:\n",
    "            print(\"第\"+str(i)+\"个因子\"+\"结果不可靠,因为多次生成数据仍不满足格式要求\\n\")\n",
    "            factor_reliable = False\n",
    "            break\n",
    "\n",
    "        print(df)\n",
    "        print('含有NaN数量：', df.iloc[:, -1].isna().sum())\n",
    "        dfs.append(df) # dfs中保存多次运行成功得到的因子列，用于之后的相关性分析\n",
    "\n",
    "    # 如果前面已经得出因子不可靠的结论，则直接进行下一个因子的处理\n",
    "    if factor_reliable == False:\n",
    "        factor_reliable_list.append([i, False])\n",
    "        continue\n",
    "\n",
    "\n",
    "    # 对同一因子的多个计算结果进行相关性分析\n",
    "    df_corr = dfs[0].set_index(['TradeDay','SecuCode'])\n",
    "    df_corr = df_corr.rename(columns={df_corr.columns[-1]: 'result_1'})\n",
    "    \n",
    "    for k in range(1, rt):\n",
    "        df_corr['result_' + str(k + 1)] = dfs[k].set_index(['TradeDay','SecuCode']).iloc[:,-1]\n",
    "\n",
    "    print('df_corr:\\n', df_corr)\n",
    "    \n",
    "    # for k in range(0, rt):\n",
    "    #     print('result_' + str(k + 1) + '含有NaN数量：', df_corr['result_' + str(k + 1)].isna().sum())\n",
    "    # print('\\n')\n",
    "    \n",
    "    \n",
    "    # print('df_corr.corr():\\n', df_corr.corr())\n",
    "\n",
    "\n",
    "    # 以向量形式得到两两列的相关系数\n",
    "    df_corr = df_corr.corr()\n",
    "    \n",
    "    correlations = [\n",
    "        df_corr.iloc[0, 1],  # col1 和 col2 的相关系数\n",
    "        df_corr.iloc[0, 2],  # col1 和 col3 的相关系数\n",
    "        df_corr.iloc[1, 2]   # col2 和 col3 的相关系数\n",
    "    ]       \n",
    "    \n",
    "    print(correlations)\n",
    "    # 检查是否有任意相关系数小于0.5\n",
    "    if any(corr < 0.5 for corr in correlations):\n",
    "        print(\"第\"+str(i)+\"个因子\"+\"结果不可靠,因为存在部分数据相关性较小\\n\")\n",
    "        factor_reliable_list.append([i, False])\n",
    "    else:\n",
    "        print(\"第\"+str(i)+\"个因子\"+\"结果可靠\\n\")\n",
    "        factor_reliable_list.append([i, True])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
